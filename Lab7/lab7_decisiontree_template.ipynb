{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "import graphviz\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>text</th> <th>tagger1</th> <th>tagger2</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>RT @Salon: Tax reform for the rich: Trumps plan abandons ...</td> <td>neu    </td> <td>neu    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>RT @calebecarma: There's video of Trump shooting paper t ...</td> <td>neu    </td> <td>neu    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>RT @IrisRimon: The NRA gave Donald Trump $30M, he told t ...</td> <td>neu    </td> <td>neu    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>RT @KeithOlbermann: NEW VIDEO: The metaphor of Trump thr ...</td> <td>neu    </td> <td>neu    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>RT @ProudResister: Trump called #StephenPaddock Pure Evi ...</td> <td>neu    </td> <td>neu    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>RT @latimes: Another Trump administration official is un ...</td> <td>neu    </td> <td>neu    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>RT @NBCPolitics: James Mattis, going against Trump campa ...</td> <td>neu    </td> <td>neu    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>RT @2020fight: Fun fact. Trump just completed his 16th t ...</td> <td>neu    </td> <td>neu    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>Mark Cuban hits Trump on tax returns, says he is 'consid ...</td> <td>neu    </td> <td>neu    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "        <tr>\n",
       "            <td>RT @thehill: Trump tosses paper towels into crowd while  ...</td> <td>neu    </td> <td>neu    </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>\n",
       "<p>... (786 rows omitted)</p"
      ],
      "text/plain": [
       "text                                                         | tagger1 | tagger2\n",
       "RT @Salon: Tax reform for the rich: Trumps plan abandons ... | neu     | neu\n",
       "RT @calebecarma: There's video of Trump shooting paper t ... | neu     | neu\n",
       "RT @IrisRimon: The NRA gave Donald Trump $30M, he told t ... | neu     | neu\n",
       "RT @KeithOlbermann: NEW VIDEO: The metaphor of Trump thr ... | neu     | neu\n",
       "RT @ProudResister: Trump called #StephenPaddock Pure Evi ... | neu     | neu\n",
       "RT @latimes: Another Trump administration official is un ... | neu     | neu\n",
       "RT @NBCPolitics: James Mattis, going against Trump campa ... | neu     | neu\n",
       "RT @2020fight: Fun fact. Trump just completed his 16th t ... | neu     | neu\n",
       "Mark Cuban hits Trump on tax returns, says he is 'consid ... | neu     | neu\n",
       "RT @thehill: Trump tosses paper towels into crowd while  ... | neu     | neu\n",
       "... (786 rows omitted)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data set\n",
    "data = Table.read_table('navya_data/lab7_data_nonASCII_removed.csv', sep='\\t')\n",
    "# data = pd.DataFrame.from_csv('navya_data/lab7_data.txt', sep='\\t')\n",
    "data\n",
    "\n",
    "# d = pd.read_csv(open('navya_data/lab7_data.txt', 'rU'), encoding='utf', engine='c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate irrelevant and relevant tweets data\n",
    "### TODO: complete the where clauses. You may use multiple of them\n",
    "data_irrelevant = data.where()\n",
    "data_relevant = data.where()\n",
    "### END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select NUM_TRAIN relevant and NUM_TRAIN irrelevant as training data, total NUM_TRAIN*2\n",
    "# NUM_TEST relevant and NUM_TEST irrelevant as testing data, total NUM_TEST*2\n",
    "\n",
    "### TODO: Assign proper numbers to NUM_TRAIN and NUM_TEST\n",
    "NUM_TRAIN = None\n",
    "NUM_TEST = None\n",
    "### END\n",
    "\n",
    "assert NUM_TRAIN + NUM_TEST <= data_irrelevant.num_rows\n",
    "assert NUM_TRAIN + NUM_TEST <= data_relevant.num_rows\n",
    "\n",
    "relevant_rows = list(range(data_relevant.num_rows))\n",
    "random.shuffle(relevant_rows)\n",
    "relevant_rows_train = relevant_rows[:NUM_TRAIN]\n",
    "relevant_rows_test = relevant_rows[-NUM_TEST:]\n",
    "\n",
    "irrelevant_rows = list(range(data_irrelevant.num_rows))\n",
    "random.shuffle(irrelevant_rows)\n",
    "irrelevant_rows_train = irrelevant_rows[:NUM_TRAIN]\n",
    "irrelevant_rows_test = irrelevant_rows[-NUM_TEST:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct actual train and test datasets: X_train, y_train, X_test, y_test\n",
    "\n",
    "X_train = list(data_relevant.take(relevant_rows_train)['text']) + \\\n",
    "    list(data_irrelevant.take(irrelevant_rows_train)['text'])\n",
    "y_train = [1] * NUM_TRAIN + [0] * NUM_TRAIN\n",
    "\n",
    "print('X_train size:', len(X_train))\n",
    "print('X_train first 5 elements:', X_train[:5])\n",
    "print('\\ny_train size:', len(y_train))\n",
    "print('y_train:', y_train)\n",
    "\n",
    "X_test = list(data_relevant.take(relevant_rows_test)['text']) + \\\n",
    "    list(data_irrelevant.take(irrelevant_rows_test)['text'])\n",
    "y_test = [1] * NUM_TEST + [0] * NUM_TEST\n",
    "\n",
    "print('\\nX_test size', len(X_test))\n",
    "print('y_test size', len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract bag of words features\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "print(X_train_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit (train) the classifier\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "X_test_counts = count_vect.transform(X_test) # Use transform instead of fit_transform\n",
    "predicted = clf.predict(X_test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple report\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed report\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "metrics.confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative method using Pipeline\n",
    "# create and fit (train)\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), \n",
    "                     ('clf', tree.DecisionTreeClassifier())])\n",
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "predicted = text_clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, feature_names=count_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inline plot\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to pdf\n",
    "graph.render('tree')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
